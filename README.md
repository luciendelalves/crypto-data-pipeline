# ğŸš€ Crypto Data Pipeline

Pipeline completo de Engenharia de Dados para coleta, transformaÃ§Ã£o e visualizaÃ§Ã£o de dados de criptomoedas em tempo real.

## ğŸ“Š Arquitetura
```
API CoinGecko â†’ Python Script â†’ PostgreSQL (Raw) â†’ dbt (TransformaÃ§Ã£o) â†’ PostgreSQL (Analytics) â†’ Metabase (Dashboard)
                                        â†“
                                Apache Airflow (OrquestraÃ§Ã£o)
```

## ğŸ› ï¸ Tecnologias Utilizadas

- **Docker & Docker Compose** - ContainerizaÃ§Ã£o
- **Apache Airflow** - OrquestraÃ§Ã£o de pipelines
- **PostgreSQL** - Data Warehouse
- **dbt (data build tool)** - TransformaÃ§Ã£o de dados
- **Metabase** - VisualizaÃ§Ã£o e dashboards
- **Python** - Scripts de extraÃ§Ã£o
- **CoinGecko API** - Fonte de dados

## ğŸ—ï¸ Estrutura do Projeto
```
crypto-pipeline/
â”œâ”€â”€ dags/                          # DAGs do Airflow
â”‚   â”œâ”€â”€ crypto_pipeline_dag.py     # Pipeline de extraÃ§Ã£o
â”‚   â””â”€â”€ crypto_pipeline_complete.py # Pipeline completo (extraÃ§Ã£o + transformaÃ§Ã£o)
â”œâ”€â”€ scripts/                       # Scripts Python
â”‚   â”œâ”€â”€ extract_crypto_data.py     # ExtraÃ§Ã£o de dados da API
â”‚   â””â”€â”€ init_db.sql               # InicializaÃ§Ã£o do banco
â”œâ”€â”€ dbt/                          # Projeto dbt
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ staging/              # Camada Silver (dados limpos)
â”‚   â”‚   â”‚   â”œâ”€â”€ stg_crypto_prices.sql
â”‚   â”‚   â”‚   â””â”€â”€ schema.yml
â”‚   â”‚   â””â”€â”€ marts/                # Camada Gold (mÃ©tricas de negÃ³cio)
â”‚   â”‚       â””â”€â”€ crypto_metrics.sql
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â””â”€â”€ profiles.yml
â””â”€â”€ docker-compose.yml            # ConfiguraÃ§Ã£o dos containers
```

## ğŸ¯ Camadas de Dados (Medallion Architecture)

### ğŸ¥‰ Bronze Layer (Raw)
- Dados brutos da API CoinGecko
- Schema: `raw.crypto_prices`
- AtualizaÃ§Ã£o: A cada 15 minutos

### ğŸ¥ˆ Silver Layer (Staging)
- Dados limpos e padronizados
- Schema: `staging.stg_crypto_prices`
- ValidaÃ§Ãµes de qualidade aplicadas

### ğŸ¥‡ Gold Layer (Analytics)
- MÃ©tricas prontas para negÃ³cio
- Schema: `analytics.crypto_metrics`
- Inclui:
  - ClassificaÃ§Ã£o de volatilidade (Alta/MÃ©dia/Baixa)
  - CategorizaÃ§Ã£o de market cap (Large/Mid/Small Cap)
  - IdentificaÃ§Ã£o de tendÃªncias (Subindo/Caindo/EstÃ¡vel)

## ğŸš€ Como Executar

### PrÃ©-requisitos
- Docker Desktop instalado
- 8GB de RAM disponÃ­vel
- Portas livres: 5433, 8081, 3001

### Passo a Passo

1. **Clone o repositÃ³rio:**
```bash
git clone https://github.com/SEU_USUARIO/crypto-data-pipeline.git
cd crypto-data-pipeline
```

2. **Suba os containers:**
```bash
docker-compose up -d
```

3. **Aguarde 2-3 minutos para inicializaÃ§Ã£o**

4. **Acesse as interfaces:**
- **Airflow:** http://localhost:8081 (user: `admin` / pass: `admin`)
- **Metabase:** http://localhost:3001

5. **Ative a DAG no Airflow:**
- Procure por `crypto_pipeline_complete`
- Ative o toggle
- Clique em â–¶ï¸ para executar manualmente

## ğŸ“Š Dashboards DisponÃ­veis

### Dashboard Crypto (Metabase)
- **Top 10 Criptomoedas** - Ranking por market cap
- **VariaÃ§Ã£o 24h** - GrÃ¡fico de barras
- **TendÃªncias** - AnÃ¡lise de volatilidade e categorizaÃ§Ã£o

## ğŸ”„ Pipeline Automatizado

O Airflow executa automaticamente:
1. **ExtraÃ§Ã£o** - Busca dados da API CoinGecko
2. **TransformaÃ§Ã£o** - Roda modelos dbt
3. **FrequÃªncia** - A cada 15 minutos
4. **Retry** - 1 tentativa com delay de 5 minutos

## ğŸ“ˆ MÃ©tricas do Pipeline

- **Tempo mÃ©dio de execuÃ§Ã£o:** ~1 minuto
- **Volume de dados:** 20 criptomoedas por execuÃ§Ã£o
- **Uptime:** 24/7
- **LatÃªncia:** < 2 minutos (API â†’ Dashboard)

## ğŸ“ Aprendizados

Este projeto demonstra:
- âœ… ExtraÃ§Ã£o de dados de APIs REST
- âœ… Modelagem dimensional (Star Schema)
- âœ… TransformaÃ§Ãµes SQL com dbt
- âœ… OrquestraÃ§Ã£o com Airflow
- âœ… ContainerizaÃ§Ã£o com Docker
- âœ… Versionamento de cÃ³digo
- âœ… DocumentaÃ§Ã£o tÃ©cnica

## ğŸ“ PrÃ³ximas Melhorias

- [ ] Adicionar testes de qualidade de dados (dbt tests)
- [ ] Implementar alertas (Slack/Email)
- [ ] Criar snapshot para anÃ¡lise histÃ³rica
- [ ] Adicionar mais fontes de dados
- [ ] Implementar CI/CD

## ğŸ‘¨â€ğŸ’» Autor

**Luciendel Alves**
- GitHub: [@luciendelalves](https://github.com/luciendelalves)
- LinkedIn: [Luciendel Alves](https://www.linkedin.com/in/luciendelalves/)

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT.